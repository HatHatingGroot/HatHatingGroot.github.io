---
title: "Deep Learning - Intro"
categories:
  - DL-ML
tags:
  - deeplearning
  - intro
last_modified_at: 2021-08-09T00:00:00-00:00
---

## Summary ğŸ¤™
---
ë”¥ëŸ¬ë‹ì—ì„œ í•™ìŠµí•œë‹¤ëŠ” ê²ƒì€ ë¬´ì—‡ì¸ì§€, ë˜ ì–´ë–¤ ì—­ì‚¬ì  íë¦„ì†ì—ì„œ ë°œì „í•´ì™”ëŠ”ì§€ë¥¼ ê°€ë³ê²Œ ì•Œì•„ë³´ì.


## Index ğŸ‘€       
  * [AI-ML-DL](#ai-ml-dl)
  * [Key Component](#key-component)
  * [Historical Review](#historical-review)
    
    
## AI-ML-DL ğŸ¤·
---
AIëŠ” MLì„ í¬í•¨í•˜ê³ , MLì€ DLë¥¼ í¬í•¨í•œë‹¤. ê°ê°ì˜ ë²”ì£¼ì— ëŒ€í•´ ê°„ëµíˆ ìš”ì•½í•˜ìë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.   
* AI(Artificial Intelligence) : ì¸ê°„ì˜ ì‚¬ê³ ë¥¼ í‰ë‚´ë‚´ëŠ” ê¸°ìˆ    
* ML(Machine Learning) : ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµí•˜ëŠ” ê¸°ìˆ    
* DL(Deep Learning) : Neural Networkë¥¼ í™œìš©í•˜ì—¬ í•™ìŠµí•˜ëŠ” ê¸°ìˆ    
  


## Key Component ğŸ§‘â€ğŸ«
---
ë”¥ëŸ¬ë‹ì„ ì´ë£¨ëŠ” ì£¼ìš”í•œ ì»´í¬ë„ŒíŠ¸ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ë¶„ë¥˜í•  ìˆ˜ ìˆë‹¤.   
1. Data   
   í’€ê³ ì í•˜ëŠ” ë¬¸ì œì— ë”°ë¼ ì •ì˜ëœë‹¤.
   * Classification
   * Semantic Segmentation
   * Detection
   * Pose Estimation
   * Visual QnA
2. Model  
   í•™ìŠµì„ ìœ„í•œ ëª¨ë¸ì´ë‹¤.
   * AlexNet
   * GoogleNet
   * ResNet
   * DenseNet
   * LSTM
   * Deep AutoEncoder
   * GAN
3. Loss
   ì •ë‹´ê³¼ì˜ ì˜¤ì°¨, ì¦‰, ë¹„ìš©ì´ë¼ê³  í• ìˆ˜ ìˆìœ¼ë©° ìµœì†Œí™”í•˜ëŠ” ê²ƒì´ ëª©í‘œë‹¤.
   * MSE(Mean Square Error): Regression
   * CE(Cross Entrophy): Classification
   * MLE(Most Likelihood Estimation) : Probabilistic
4. Algorithm
   ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•œ ì•Œê³ ë¦¬ì¦˜ì´ë‹¤.
   * SGD


## Historical Review ğŸ‘
---
> [Deep Learning's Most Important Ideas](https://dennybritz.com/blog/deep-learning-most-important-ideas) - A Brief Historical Review (Denny Britz, 2020-07-29)   
* 2012 - AlextNet 
* 2013 - DQN
* 2014 - Encoder/Decoder(NMT), Adam 
* 2015 - GAN(ìˆ ì§‘), ResNet(DLë¥¼ ê°€ëŠ¥ì¼€ í•¨)
* 2017 - Transformer (Attention is All you need)
* 2018 - BERT(fine-tuned NLP models)
* 2019 - GPT-3(OpenAI)
* 2020 - Self Supervised Learning(ë¹„ì§€ë„ í•™ìŠµ)SimCLR (a simple framework for contrastive learing of visual represenations)
