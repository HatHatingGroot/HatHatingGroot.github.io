---
title: "Boostcamp AI tech 2주차 회고"
categories:
  - Boostcamp
tags:
  - Boostcamp
  - aitech
last_modified_at: 2021-08-10T00:00:00-00:00
---


## Summary 🤙
---
1주차는 Python 기본과 AI Math의 주제로 강의가 구성되었다. 프로그래밍은 익숙한 편이라, AI Math에 최대한 많은 시간을 투자했다. 각 용어들의 정의에 익숙해지는데 집중했고, 여러번 자주 접하여 익숙해지기 위한 시간이었다.   

## Keywords 👀     
  * [[DL/ML]Deep Learning - Intro](#)
  * [[DL/ML]Optimization - Important Concept](#)
  * [[DL/ML]Gradient Descent Methods](#)

## Tasks 🤷
---


## Topic of Peer Session  🧑‍🏫
---
1. 참고사이트
   1. [3Blue1Brown](https://www.youtube.com/channel/UCYO_jab_esuFRV4b17AJtAw)
2. 라그랑주 승수법
3. 가능도가 평균에 비해 가지는 이점 : 모수를 모르더라도 데이터로 추정 가능
4. [머신러닝 관점에서의 통계학](https://devkihyun.github.io/study/Machine-learining-and-Probability/)
5. 로그 가능도 계산 시 정확도 문제 : 극값의 위치가 같아 문제없다. 
6. 쿨백 라이블러 발산이 음수가 될 가능성
7. 가능도는 반드시 모수의 분포를 가정해야하는가: 기본적으로 모수적인 데이터 밀도 추정 방법으로 가정이 필요하다.
8. BPTT

## Retrospective 👍
---
1. 개념에 대한 정리는 적어도 2일에 한번씩 진행해야 할것 같다. (2일 이상 지나면 키워드 위주 메모해놓은 것이 기억이 안난다...👀)   
2. 수학은 바라보는 관점(feat. 임성빈 교수님, sungbin@unist.ac.kr)
   1. 익숙해져야한다.
   2. 많이 보는 것보다 많이 사용해봐야 한다.
      1. 용어와 정의는 일단 외운다.
      2. 예제를 찾는다.
   3. 오랜시간을 집중해서 보기보다는 짧게 자주, 머리를 적신다는 느낌으로
   4. 실제 해당 이론을 사용해야할 때 깊게 파라
   5. 선형대수, 확률론, 통계학과 아주 조금의 미적분(Gradient discent)
   6. 책 추천 : [Dive into Deep Learning](https://d2l.ai)
   7. 추천시스템 학습 키워드 
      1. MAB (Multi-armed Bandit)
      2. d2l chap16
   8. 논문 구현하는 연습이 필요하다.
      1. 오픈소스가 아닌 논문 구현 후 성능 비교
3. 

