---
title: "RNN(Recurrent Neural Network) Intro"
categories:
  - RNN
  - ML/DL
tags:
  - rnn
  - bptt
  - gradientdescent
last_modified_at: 2021-08-06T00:00:00-00:00
use_math: true
---

## memo(tmp)
1. i.i.d. : Independently and Identically distributed
2. CNNì€ ê³µê°„ì •ë³´(spatial information)ì— íš¨ìœ¨ì ì¸ ë°˜ë©´, RNNì€ ì‹œí€€ìŠ¤ ì •ë³´ì— ë” ì í•©í•˜ë‹¤.
   1. RNNì€ ê³¼ê±° ì •ë³´ì™€ í˜„ì¬ ì…ë ¥ ì •ë³´ë¥¼ ëª¨ë‘ ê°€ì§€ëŠ” state ë³€ìˆ˜ë¥¼ í†µí•´ í˜„ì¬ì˜ ouputì„ ì •í•œë‹¤
3. RNNì€ ì‹œê³„ì—´ ë°ì´í„°, ì£¼ì‹ì‹œì¥ ë¶„ì„ë“±ì— í™œìš©ëœë‹¤.
4. ì£¼ê°€ë¥¼ ì˜ˆë¡œ ë“¤ë©´ íŠ¹ì • ì‹œê°„ tì—ì„œì˜ x_të¥¼ ì˜ˆì¸¡í•˜ê³ ì í•œë‹¤ë©´
   1. $$ x_t ~ P(x_t|x_{t-1}, \cdots , x_1) $$
5. ì—¬ê¸°ì„œ ë¬¸ì œëŠ” t-1 ~ 1ì˜ ëª¨ë“  ì‹œí€€ìŠ¤ê°€ ê³ ë ¤í•˜ëŠ” ê²ƒì€ í˜ë“¤ê¸° ë•Œë¬¸ì— ë‹¤ìŒì˜ ì „ëµìœ¼ë¡œ ê°„ì†Œí™” í• ìˆ˜ ìˆë‹¤.
   1. t-1 ~ 1ì˜ ëª¨ë“  ì‹œí€€ìŠ¤ ë°ì´í„°ê°€ í•„ìš”í•œê²ƒì´ ì•„ë‹ˆë¼ë©´ $\tau$ ë§Œí¼ì˜ íŠ¹ì • êµ¬ê°„ì„ ì •í•˜ì—¬ $x_{t-1}, \cdots , x_{t-\tau}$ë§Œ ê´€ì¸¡í•œë‹¤.
   2. tì—ì„œì˜ hiddent state $h_t$ë¥¼ í†µí•´ ì—…ë°ì´íŠ¸
   3. $P\left(x_{1}, \ldots, x_{T}\right)=\prod_{t=1}^{T} P\left(x_{t} \mid x_{t-1}, \ldots, x_{1}\right)$







## Summary ğŸ¤™
---
Gradient Descent (ê²½ì‚¬í•˜ê°•ë²•)ë¥¼ í†µí•´ í•¨ìˆ˜ fì˜ ê·¹ì†Œê°’ì— ë„ë‹¬í•  ìˆ˜ ìˆë‹¤.


## Index ğŸ‘€       
  * [Why](#why)
  * [Definition](#definition)
  * [Feature](#feature)
  * [Use Cases](#use-cases)
  * [Related](#related)
  * [Implementation](#implementation)

## Why ğŸ¤·
---
ê¸°ê³„ í•™ìŠµì—ì„œ ì£¼ë¡œ ì‚¬ìš©ë˜ëŠ” íŒ¨í„´ì€ íŠ¹ì • í•¨ìˆ˜ë¥¼ ìµœì†Œí™”í•˜ê¸° ìœ„í•´ ë°˜ë³µì ì¸ ê³„ì‚°ì„ ìˆ˜í–‰í•˜ëŠ” ê²ƒì´ë‹¤. Linear Regressionì„ ìœ„í•´ Lossí•¨ìˆ˜ë¥¼ ìµœì†Œí™” í•˜ëŠ” ê²ƒì´ ëŒ€í‘œì ì¸ ì˜ˆì´ë‹¤. 
ë˜í•œ Gradient DescentëŠ” ëª¨ë“  ì°¨ì›ê³¼ ê³µê°„ì—ì„œ ì ìš©ì´ ê°€ëŠ¥í•˜ë‹¤. 



## Definition ğŸ§‘â€ğŸ«
---
ë³€ìˆ˜ $x$ì— ëŒ€í•´ $f(x)$ì˜ ê·¹ì†Ÿê°’ì€ $f(x_k-f'(x_k))$ê°€ 0ì´ ë  ë•Œê¹Œì§€ ë°˜ë³µì ìœ¼ë¡œ ìˆ˜í–‰í•˜ë©´ ë„ë‹¬í•  ìˆ˜ ìˆë‹¤.


## Feature ğŸ‘
---
TODO 


## Use Cases ğŸª¢
---
TODO  


## Related ğŸ§¶
---
TODO 


## Implementation ğŸ˜
---
```python
# 1ì°¨ì›
import sympy as sym
from sympy.abc import x

f = sym.poly(x**2 + 2*x + 3)

val = init_value
grad = sym.diff(f)
```